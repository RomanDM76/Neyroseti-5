{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 80)\n",
      "x_test shape: (25000, 80)\n",
      "Построение модели...\n",
      "Процесс обучения...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roman/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/50\n",
      "25000/25000 [==============================] - 208s 8ms/step - loss: 0.1597 - accuracy: 0.7669 - val_loss: 0.1164 - val_accuracy: 0.8381\n",
      "Epoch 2/50\n",
      "25000/25000 [==============================] - 207s 8ms/step - loss: 0.0918 - accuracy: 0.8774 - val_loss: 0.1173 - val_accuracy: 0.8374\n",
      "Epoch 3/50\n",
      "25000/25000 [==============================] - 207s 8ms/step - loss: 0.0714 - accuracy: 0.9076 - val_loss: 0.1271 - val_accuracy: 0.8273\n",
      "Epoch 4/50\n",
      "25000/25000 [==============================] - 207s 8ms/step - loss: 0.0610 - accuracy: 0.9222 - val_loss: 0.1311 - val_accuracy: 0.8278\n",
      "Epoch 5/50\n",
      "25000/25000 [==============================] - 207s 8ms/step - loss: 0.0510 - accuracy: 0.9362 - val_loss: 0.1363 - val_accuracy: 0.8188\n",
      "Epoch 6/50\n",
      "25000/25000 [==============================] - 210s 8ms/step - loss: 0.0412 - accuracy: 0.9501 - val_loss: 0.1434 - val_accuracy: 0.8172\n",
      "Epoch 7/50\n",
      "25000/25000 [==============================] - 215s 9ms/step - loss: 0.0313 - accuracy: 0.9625 - val_loss: 0.1455 - val_accuracy: 0.8200\n",
      "Epoch 8/50\n",
      "25000/25000 [==============================] - 213s 9ms/step - loss: 0.0261 - accuracy: 0.9691 - val_loss: 0.1491 - val_accuracy: 0.8160\n",
      "Epoch 9/50\n",
      "25000/25000 [==============================] - 209s 8ms/step - loss: 0.0257 - accuracy: 0.9699 - val_loss: 0.1535 - val_accuracy: 0.8110\n",
      "Epoch 10/50\n",
      "25000/25000 [==============================] - 209s 8ms/step - loss: 0.0216 - accuracy: 0.9755 - val_loss: 0.1540 - val_accuracy: 0.8173\n",
      "Epoch 11/50\n",
      "25000/25000 [==============================] - 211s 8ms/step - loss: 0.0196 - accuracy: 0.9780 - val_loss: 0.1590 - val_accuracy: 0.8130\n",
      "Epoch 12/50\n",
      "25000/25000 [==============================] - 210s 8ms/step - loss: 0.0193 - accuracy: 0.9778 - val_loss: 0.1622 - val_accuracy: 0.8125\n",
      "Epoch 13/50\n",
      "25000/25000 [==============================] - 217s 9ms/step - loss: 0.0175 - accuracy: 0.9800 - val_loss: 0.1632 - val_accuracy: 0.8128\n",
      "Epoch 14/50\n",
      "25000/25000 [==============================] - 212s 8ms/step - loss: 0.0158 - accuracy: 0.9819 - val_loss: 0.1670 - val_accuracy: 0.8080\n",
      "Epoch 15/50\n",
      "25000/25000 [==============================] - 217s 9ms/step - loss: 0.0157 - accuracy: 0.9819 - val_loss: 0.1701 - val_accuracy: 0.8068\n",
      "Epoch 16/50\n",
      "25000/25000 [==============================] - 212s 8ms/step - loss: 0.0147 - accuracy: 0.9833 - val_loss: 0.1679 - val_accuracy: 0.8114\n",
      "Epoch 17/50\n",
      "25000/25000 [==============================] - 207s 8ms/step - loss: 0.0153 - accuracy: 0.9824 - val_loss: 0.1655 - val_accuracy: 0.8121\n",
      "Epoch 18/50\n",
      "25000/25000 [==============================] - 207s 8ms/step - loss: 0.0116 - accuracy: 0.9867 - val_loss: 0.1614 - val_accuracy: 0.8136\n",
      "Epoch 19/50\n",
      "25000/25000 [==============================] - 218s 9ms/step - loss: 0.0106 - accuracy: 0.9884 - val_loss: 0.1645 - val_accuracy: 0.8132\n",
      "Epoch 20/50\n",
      "25000/25000 [==============================] - 215s 9ms/step - loss: 0.0105 - accuracy: 0.9884 - val_loss: 0.1632 - val_accuracy: 0.8146\n",
      "Epoch 21/50\n",
      "25000/25000 [==============================] - 208s 8ms/step - loss: 0.0084 - accuracy: 0.9912 - val_loss: 0.1710 - val_accuracy: 0.8095\n",
      "Epoch 22/50\n",
      "25000/25000 [==============================] - 213s 9ms/step - loss: 0.0088 - accuracy: 0.9904 - val_loss: 0.1673 - val_accuracy: 0.8114\n",
      "Epoch 23/50\n",
      " 7552/25000 [========>.....................] - ETA: 1:50 - loss: 0.0086 - accuracy: 0.9905"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Dropout\n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "max_features = 20000\n",
    "\n",
    "# обрезание текстов после данного количества слов (среди top max_features наиболее используемые слова)\n",
    "maxlen = 80\n",
    "batch_size = 128 # увеличьте значение для ускорения обучения\n",
    "\n",
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')\n",
    "\n",
    "print('Pad последовательности (примеров в x единицу времени)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
    "model.compile(loss='mean_squared_error', # loss='binary_crossentropy' прогоны 1-4\n",
    "              optimizer='adam', # optimizer='adam' прогон 4\n",
    "              metrics=['accuracy']) # metrics=['accuracy'])\n",
    "\n",
    "print('Процесс обучения...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=50, # увеличьте при необходимости\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
